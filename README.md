# Bidirectional Human-AI Alignment - Reading List


This repository lists papers on **[Bidirectional Human-AI Alignment](https://arxiv.org/pdf/2406.09264)** [Paper](https://arxiv.org/pdf/2406.09264) research, primarily covering papers in Human-Computer Interaction (HCI), Natural Language Processing (NLP) and Machine Learng (ML) fields. 

<!-- Reference: https://github.com/zhijing-jin/Causality4NLP_Papers -->


**Contributor:** [Hua Shen](https://hua-shen.org/).
Welcome to be a collaborator, -- you can make an issue/pull request, and I can add you :).


### Contents (Actively Updating)



- [1. Human Values and Specifications](#1-human-values)
  - [1.1 Human Value Category](#11-human-value-category)
    - [1.1.1 Source of Values](#111-source)
    - [1.1.2 Value Types](#112-types)
  - [1.2 Interaction Techniques to Specify AI Values](#12-value-pecification)
    - [1.2.1 Explicit Human Feedback](#121-explicit-feedback)
    - [1.2.2 Implicit Human Feedback](#122-implicit-feedback)
    - [1.2.3 Simulated Human Value Feedback](#123-simulated-feedback)

  
- [2. Integrating Human Specifications into AI](#2-integrate-ai)
  - [2.1 Develop AI with General Values](#21-human-value-category)
    - [2.1.1 Instruction Data](#211-instruction-data)
    - [2.1.2 Model Learning](#212-model-learning)
    - [2.1.3 Inference Stage](#213-inference-stage)
  - [2.2 Customizing AI for Individuals and Groups](#22-customize-ai)
    - [2.2.1 Customized Data](#221-customize-data)
    - [2.2.2 Adapt Model by Learning](#222-adapt-model-by-learning)
    - [2.2.3 Interactive Alignment](#223-interactive-alignment)
  - [2.3 Evaluating AI Systems](#23-evaluate-ai)
    - [2.3.1 Human-In-The-Loop-Evaluation](#231-hitl-eval)
    - [2.3.2 Automatic Evaluation](#232-auto-eval)
  - [2.4 Ecosystem](#24-ecosystem)
    - [2.4.1 Platforms](#241-platforms)
    

- [3.Human Cognitive Adjustment to AI](#3-cognitive-adjustment)
  - [3.1 Perceiving and Understanding of AI](#31-perceive)
    - [3.1.1 Education and Training Human](#311-education-training)
    - [3.1.2 AI Sensemaking and Explanations](#312-ai-sensemaking)
  - [3.2 Critical Thinking about AI](#32-critical-thinking)
    - [3.2.1 Trust and Reliance on AI Decisions](#321-trust-reliance)
    - [3.2.2 Ethical Concerns and AI Auditing](#322-ethical-audit)
    - [3.2.3 Calibrate Cognition to Align AI](#323-calibrate-ai)


- [4. Human Adaptive Behavior to AI](#4-behavioral-adapation)
  - [4.1 Human Collaborating with Diverse AI Roles](#41-human-ai-collaboration)
    - [4.1.1 Assistants](#411-assistants)
    - [4.1.2 Partners](#412-partners)
    - [4.1.3 Tutors](#413-tutors)
  - [4.2 AI Impacts on Human and Society](#42-ai-impacts)
    - [4.2.1 Impact on Individual Behavior](#421-impact-on-individual)
    - [4.2.2 Societal Concerns and AI Impacts](#422-social-impacts)
    - [4.2.3 Reaction to AI Advancements](#423-reaction-to-ai)
  - [4.3 Evaluation in Human Studies](#43-evaluation)
    - [4.3.1 Evaluate Human-AI Collaboration](#431-evaluate-collaborate)
    - [4.3.2 Evaluate Societal Impact](#432-eval-social-impacts)


- [5. Others - To Add More...](#5-more)







## 1. Human Values and Specifications

### 1.1 Human Value Category

#### 1.1.1 Source of Values

**Individuals:**
1. (2021 CHI) **Human perceptions on moral responsibility of AI: A case study in AI-assisted bail decision-making**. *Lima, Gabriel, Nina Grgić-Hlača, and Meeyoung Cha*. [[pdf]](https://dl.acm.org/doi/pdf/10.1145/3411764.3445260?casa_token=1f8C9397M5UAAAAA:axhwwncFHhzsQgRueN8OER4kJuAGVO61zL7ic3OJviG-8FYuPY3dbdzh77M05Ko0xXi3RhU6h9T4)


**Society:**



**Interaction:**




#### 1.1.2 Value Types

### 1.2 Interaction Techniques to Specify AI Values

#### 1.2.1 Explicit Human Feedback

#### 1.2.2 Implicit Human Feedback

#### 1.2.3 Simulated Human Value Feedback




## 2. Integrating Human Specifications into AI

### 2.1 Develop AI with General Values

#### 2.1.1 Instruction Data
#### 2.1.2 Model Learning
#### 2.1.3 Inference Stage


### 2.2 Customizing AI for Individuals and Groups
#### 2.2.1 Customized Data
#### 2.2.2 Adapt Model by Learning
#### 2.2.3 Interactive Alignment


### 2.3 Evaluating AI Systems
#### 2.3.1 Human-In-The-Loop-Evaluation
#### 2.3.2 Automatic Evaluation


### 2.4 Ecosystem
#### 2.4.1 Platforms




## 3.Human Cognitive Adjustment to AI

### 3.1 Perceiving and Understanding of AI

#### 3.1.1 Education and Training Human

#### 3.1.2 AI Sensemaking and Explanations


### 3.2 Critical Thinking about AI

#### 3.2.1 Trust and Reliance on AI Decisions
#### 3.2.2 Ethical Concerns and AI Auditing
#### 3.2.3 Calibrate Cognition to Align AI


## 4. Human Adaptive Behavior to AI

### 4.1 Human Collaborating with Diverse AI Roles
#### 4.1.1 Assistants
#### 4.1.2 Partners
#### 4.1.3 Tutors

### 4.2 AI Impacts on Human and Society
#### 4.2.1 Impact on Individual Behavior
#### 4.2.2 Societal Concerns and AI Impacts
#### 4.2.3 Reaction to AI Advancements

### 4.3 Evaluation in Human Studies
#### 4.3.1 Evaluate Human-AI Collaboration
#### 4.3.2 Evaluate Societal Impact







<!-- ## 1. Causality Basics

### 1.3 Toolboxes

#### Causal Discovery

1. (2021) **causal-learn (Python package for causal discovery).** _Carnegie Mellon University_. [[GitHub](https://github.com/cmu-phil/causal-learn)] [[documentation](https://causal-learn.readthedocs.io/en/latest/)] 
3. (2019) **Causal Discovery Toolbox in Python.** [[GitHub](https://github.com/FenTechSolutions/CausalDiscoveryToolbox)] [[pdf](https://arxiv.org/pdf/1903.02278.pdf)] 
4. **Causal discovery tools.** _University of Pittsburgh/Carnegie Mellon University Center for Causal Discovery_. [[link](https://www.ccd.pitt.edu/tools/)]
   <br>e.g., Tretrad, [py-causal](https://bd2kccd.github.io/docs/py-causal/)  -->








## How to Cite This Repo

If you find the repository helpful to your research and would like to cite it, please see the `bibtex` below:

```bibtex
@article{shen2024towards,
  title={Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions},
  author={Shen, Hua and Knearem, Tiffany and Ghosh, Reshmi and Alkiek, Kenan and Krishna, Kundan and Liu, Yachuan and Ma, Ziqiao and Petridis, Savvas and Peng, Yi-Hao and Qiwei, Li and Rakshit, Sushrita and Si, Chenglei and Xie, Yutong and Bigham, Jeffrey P. and Bentley, Frank and Chai, Joyce and Lipton, Zachary and Mei, Qiaozhu and Mihalcea, Rada and Terry, Michael and Yang, Diyi and Morris, Meredith Ringel and Resnick, Paul and Jurgens, David},
  journal={arXiv preprint arXiv:2406.09264},
  year={2024}
}
```






<!-- 
- [1. Causality Basics](#1-causality-basics)
  - [1.1 Talks/Tutorial/etc](#11-Talkstutorialetc)
  - [1.2 Overview Papers](#12-overview-papers)
  - [1.3 Toolboxes](#13-toolboxes)
   -->


<!-- 
- [1. Causality Basics](#1-causality-basics)
  - [1.1 Talks/Tutorial/etc](#11-Talkstutorialetc)
  - [1.2 Overview Papers](#12-overview-papers)
  - [1.3 Toolboxes](#13-toolboxes)
- [2. Causality Applied to General NLP](#2-causality-applied-to-general-nlp)
  - [2.1 Causality to Bring Insights to NLP Modeling (for Robustness, Domain Adaptation, etc)](#21-causality-to-bring-insights-to-nlp-modeling-for-robustness-domain-adaptation-etc)
  - [2.2 Language Model Analysis in a Causal Way (for Probing, Interpretability, etc.)](#22-language-model-analysis-in-a-causal-way-for-probing-interpretability-etc)
  - [2.3 Text Features in Causal Graphs (for Social Science, Psychology, etc.)](#23-text-features-in-causal-graphs-for-social-science-psychology-etc)
  - [2.4 Causal Relation Extraction](#24-causal-relation-extraction)
  - [2.5 Causal Commonsense Reasoning and Generation](#25-causal-commonsense-reasoning-and-generation)
- [3. Causality for Various Applications](#3-causality-for-various-applications)
  - [3.1 Persuasion](#31-persuation)
  - [3.2 Psychology and Behavior](#32-psychology-and-behavior)
  - [3.3 Economics](#33-economics)
  - [3.4 Healthcare](#34-healthcare)
  - [3.4 Judicial Decision](#35-judicial-decision)
  - [3.5 Marketing strategies and sales prediction](#36-marketing-strategies-and-sales-prediction)
- [4. More Resources](#4-more-resources)
  - [4.1 Causality Papers from Schoelkopf's Lab, MPI](#41-causality-papers-from-schoelkopfs-lab-mpi)
    - [4.1.0 Overview](#410-overview)
    - [4.1.1 Learning Causal "Units" and Mechanisms (i.e., Causal Representation Learning)](#411-learning-causal-units-and-mechanisms-ie-causal-representation-learning)
    - [4.1.2 Robustness and Invariance (incl. Semi-Supervised Learning, Covariate Shift, Transfer Learning)](#411-learning-causal-units-and-mechanisms-ie-causal-representation-learning)
    - [4.1.3 Causal Discovery](#411-learning-causal-units-and-mechanisms-ie-causal-representation-learning)
    - [4.1.4 Causal Effect Estimation](#414-causal-effect-estimation)
    - [4.1.5 Foundational work (theory, ICA, etc.)](#415-foundational-work-theory-ica-etc)
  - [4.2 Causality Papers from Bengio's Lab, MILA](#42-causality-papers-from-bengios-lab-mila)
    - [Motivational Position Papers](#motivational-position-papers)
    - [Applying Causality Knowledge for RL Interaction Design](#applying-causality-knowledge-for-rl-interaction-design)
    - [Applying causality to model design](#applying-causality-to-model-design)
    - [Causal induction from interventional data](#causal-induction-from-interventional-data)
    - [Grounded AI](#grounded-AI)
  - [4.3 Other Causality Papers (Potentially Applicable to NLP)](#43-other-causality-papers-potentially-applicable-to-nlp)
  - [4.4 Books (for Systematic Learning)](#44-books-for-systematic-learning)
  - [4.5 Online Courses](#45-online-courses)
  - [4.6 People Directory](#46-people-directory)
  - [4.7 Workshops](#47-workshops)
  - [4.8 Others](#48-others)
- [Contributions](#contributions)
- [How to Cite This Repo](#How-to-Cite-This-Repo)
 -->



